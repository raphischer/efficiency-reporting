{
    "Addepalli2021Towards_RN18": {
        "url": "https://arxiv.org/abs/2210.09852",
        "paper": "Scaling Adversarial Training to Large Perturbation Bounds",
        "architecture": "ResNet-18",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "ECCV 2022",
        "authors": "Sravanti Addepalli, Samyak Jain, Gaurang Sriramanan, Shivangi Khare, Venkatesh Babu Radhakrishnan",
        "footnote": null,
        "name": "Addepalli et al. ECCV 2022",
        "short": "Addepalli22"
    },
    "Addepalli2021Towards_WRN34": {
        "url": "https://arxiv.org/abs/2210.09852",
        "paper": "Scaling Adversarial Training to Large Perturbation Bounds",
        "architecture": "WideResNet-34-10",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "ECCV 2022",
        "authors": "Sravanti Addepalli, Samyak Jain, Gaurang Sriramanan, Shivangi Khare, Venkatesh Babu Radhakrishnan",
        "footnote": null,
        "name": "Addepalli et al. ECCV 2022",
        "short": "Addepalli22"
    },
    "Addepalli2022Efficient_RN18": {
        "url": "https://arxiv.org/abs/2210.15318",
        "paper": "Efficient and Effective Augmentation Strategy for Adversarial Training",
        "architecture": "ResNet-18",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "NeurIPS 2022",
        "authors": "Sravanti Addepalli, Samyak Jain, Venkatesh Babu Radhakrishnan",
        "footnote": null,
        "name": "Addepalli et al. NeurIPS 2022",
        "short": "Addepalli22"
    },
    "Addepalli2022Efficient_WRN_34_10": {
        "url": "https://arxiv.org/abs/2210.15318",
        "paper": "Efficient and Effective Augmentation Strategy for Adversarial Training",
        "architecture": "WideResNet-34-10",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "NeurIPS 2022",
        "authors": "Sravanti Addepalli, Samyak Jain, Venkatesh Babu Radhakrishnan",
        "footnote": null,
        "name": "Addepalli et al. NeurIPS 2022",
        "short": "Addepalli22"
    },
    "Alayrac2019Labels": {
        "url": "https://arxiv.org/abs/1905.13725",
        "paper": "Are Labels Required for Improving Adversarial Robustness?",
        "architecture": "WideResNet-28-10",
        "additional_data": "True",
        "number_forward_passes": 1,
        "venue": "NeurIPS 2019",
        "authors": "Jonathan Uesato, Jean-Baptiste Alayrac, Po-Sen Huang, Robert Stanforth, Alhussein Fawzi, Pushmeet Kohli",
        "footnote": null,
        "name": "Uesato et al. NeurIPS 2019",
        "short": "Uesato19"
    },
    "Alfarra2020ClusTR": {
        "url": "https://arxiv.org/abs/2006.07682",
        "paper": "ClusTR: Clustering Training for Robustness\n",
        "architecture": "WideResNet-28-10",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "arXiv, Jun 2020",
        "authors": "Motasem Alfarra, Juan C. Perez, Adel Bibi, Ali Thabet, Pablo Arbelaez, Bernard Ghanem",
        "footnote": null,
        "name": "Alfarra et al. arXiv, Jun 2020",
        "short": "Alfarra20"
    },
    "Andriushchenko2020Understanding": {
        "url": "https://arxiv.org/abs/2007.02617",
        "paper": "Understanding and Improving Fast Adversarial Training",
        "architecture": "PreActResNet-18",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "NeurIPS 2020",
        "authors": "Maksym Andriushchenko, Nicolas Flammarion",
        "footnote": "Focuses on fast adversarial training.",
        "name": "Andriushchenko et al. NeurIPS 2020",
        "short": "Andriushchenko20"
    },
    "Atzmon2019Controlling": {
        "url": "https://arxiv.org/abs/1905.11911",
        "paper": "Controlling Neural Level Sets",
        "architecture": "ResNet-18",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "NeurIPS 2019",
        "authors": "Matan Atzmon, Niv Haim, Lior Yariv, Ofer Israelov, Haggai Maron, Yaron Lipman",
        "footnote": "Uses \\(\\ell_{\\infty} \\) = 0.031 \u2248 7.9/255 instead of 8/255.",
        "name": "Atzmon et al. NeurIPS 2019",
        "short": "Atzmon19"
    },
    "Augustin2020Adversarial": {
        "url": "https://arxiv.org/abs/2003.09461",
        "paper": "Adversarial Robustness on In- and Out-Distribution Improves Explainability",
        "architecture": "ResNet-50",
        "additional_data": "True",
        "number_forward_passes": 1,
        "venue": "ECCV 2020",
        "authors": "Maximilian Augustin, Alexander Meinke, Matthias Hein",
        "footnote": "Extra data used only as OOD dataset.",
        "name": "Augustin et al. ECCV 2020",
        "short": "Augustin20"
    },
    "Augustin2020Adversarial_34_10": {
        "url": "https://arxiv.org/abs/2003.09461",
        "paper": "Adversarial Robustness on In- and Out-Distribution Improves Explainability",
        "architecture": "WideResNet-34-10",
        "additional_data": "True",
        "number_forward_passes": 1,
        "venue": "ECCV 2020",
        "authors": "Maximilian Augustin, Alexander Meinke, Matthias Hein",
        "footnote": "Extra data used only as OOD dataset.",
        "name": "Augustin et al. ECCV 2020",
        "short": "Augustin20"
    },
    "Augustin2020Adversarial_34_10_extra": {
        "url": "https://arxiv.org/abs/2003.09461",
        "paper": "Adversarial Robustness on In- and Out-Distribution Improves Explainability",
        "architecture": "WideResNet-34-10",
        "additional_data": "True",
        "number_forward_passes": 1,
        "venue": "ECCV 2020",
        "authors": "Maximilian Augustin, Alexander Meinke, Matthias Hein",
        "footnote": null,
        "name": "Augustin et al. ECCV 2020",
        "short": "Augustin20"
    },
    "Bai2023Improving_edm": {
        "url": "https://arxiv.org/abs/2301.12554",
        "paper": "Improving the Accuracy-Robustness Trade-off of Classifiers via Adaptive Smoothing",
        "architecture": "ResNet-152 + WideResNet-70-16 + mixing network",
        "additional_data": "True",
        "number_forward_passes": 2,
        "venue": "arXiv, Jan 2023",
        "authors": "Yatong Bai, Brendon G Anderson, Aerin Kim, Somayeh Sojoudi",
        "footnote": "It uses an ensemble of networks. The robust base classifier uses 50M synthetic images.",
        "name": "Bai et al. arXiv, Jan 2023",
        "short": "Bai23"
    },
    "Calian2021Defending": {
        "url": "https://arxiv.org/abs/2104.01086",
        "paper": "Defending Against Image Corruptions Through Adversarial Augmentations",
        "architecture": "ResNet-50",
        "additional_data": "True",
        "number_forward_passes": 1,
        "venue": "arXiv, Apr 2021",
        "authors": "Dan A. Calian, Florian Stimberg, Olivia Wiles, Sylvestre-Alvise Rebuffi, Andras Gyorgy, Timothy Mann, Sven Gowal",
        "footnote": "Uses extra data indirectly via a super resolution and autoencoder networks that were pre-trained on other datasets.",
        "name": "A. et al. arXiv, Apr 2021",
        "short": "A.21"
    },
    "Carmon2019Unlabeled": {
        "url": "https://arxiv.org/abs/1905.13736",
        "paper": "Unlabeled Data Improves Adversarial Robustness",
        "architecture": "WideResNet-28-10",
        "additional_data": "True",
        "number_forward_passes": 1,
        "venue": "NeurIPS 2019",
        "authors": "Yair Carmon, Aditi Raghunathan, Ludwig Schmidt, Percy Liang, John C. Duchi",
        "footnote": null,
        "name": "Carmon et al. NeurIPS 2019",
        "short": "Carmon19"
    },
    "Chan2020Jacobian": {
        "url": "https://arxiv.org/abs/1912.10185",
        "paper": "Jacobian Adversarially Regularized Networks for Robustness",
        "architecture": "WideResNet-34-10",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "ICLR 2020",
        "authors": "Alvin Chan, Yi Tay, Yew Soon Ong, Jie Fu",
        "footnote": null,
        "name": "Chan et al. ICLR 2020",
        "short": "Chan20"
    },
    "Chen2020Adversarial": {
        "url": "https://arxiv.org/abs/2003.12862",
        "paper": "Adversarial Robustness: From Self-Supervised Pre-Training to Fine-Tuning",
        "architecture": "ResNet-50",
        "additional_data": "False",
        "number_forward_passes": 3,
        "venue": "CVPR 2020",
        "authors": "Tianlong Chen, Sijia Liu, Shiyu Chang, Yu Cheng, Lisa Amini, Zhangyang Wang",
        "footnote": "Uses ensembles of 3 models.",
        "name": "Chen et al. CVPR 2020",
        "short": "Chen20"
    },
    "Chen2020Efficient": {
        "url": "https://arxiv.org/abs/2010.01278",
        "paper": "Efficient Robust Training via Backward Smoothing",
        "architecture": "WideResNet-34-10",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "arXiv, Oct 2020",
        "authors": "Jinghui Chen, Yu Cheng, Zhe Gan, Quanquan Gu, Jingjing Liu",
        "footnote": null,
        "name": "Chen et al. arXiv, Oct 2020",
        "short": "Chen20"
    },
    "Chen2021LTD_WRN34_10": {
        "url": "https://arxiv.org/abs/2111.02331",
        "paper": "LTD: Low Temperature Distillation for Robust Adversarial Training",
        "architecture": "WideResNet-34-10",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "arXiv, Nov 2021",
        "authors": "Erh-Chung Chen, Che-Rung Lee",
        "footnote": null,
        "name": "Chen et al. arXiv, Nov 2021",
        "short": "Chen21"
    },
    "Chen2021LTD_WRN34_20": {
        "url": "https://arxiv.org/abs/2111.02331",
        "paper": "LTD: Low Temperature Distillation for Robust Adversarial Training",
        "architecture": "WideResNet-34-20",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "arXiv, Nov 2021",
        "authors": "Erh-Chung Chen, Che-Rung Lee",
        "footnote": null,
        "name": "Chen et al. arXiv, Nov 2021",
        "short": "Chen21"
    },
    "Cui2020Learnable_34_10": {
        "url": "https://arxiv.org/abs/2011.11164",
        "paper": "Learnable Boundary Guided Adversarial Training",
        "architecture": "WideResNet-34-10",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "ICCV 2021",
        "authors": "Jiequan Cui, Shu Liu, Liwei Wang, Jiaya Jia",
        "footnote": "Uses \\(\\ell_{\\infty} \\) = 0.031 \u2248 7.9/255 instead of 8/255",
        "name": "Cui et al. ICCV 2021",
        "short": "Cui21"
    },
    "Cui2020Learnable_34_20": {
        "url": "https://arxiv.org/abs/2011.11164",
        "paper": "Learnable Boundary Guided Adversarial Training",
        "architecture": "WideResNet-34-20",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "ICCV 2021",
        "authors": "Jiequan Cui, Shu Liu, Liwei Wang, Jiaya Jia",
        "footnote": "Uses \\(\\ell_{\\infty} \\) = 0.031 \u2248 7.9/255 instead of 8/255",
        "name": "Cui et al. ICCV 2021",
        "short": "Cui21"
    },
    "Cui2023Decoupled_WRN-28-10": {
        "url": "https://arxiv.org/abs/2305.13948",
        "paper": "Decoupled Kullback-Leibler Divergence Loss",
        "architecture": "WideResNet-28-10",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "arXiv, May 2023",
        "authors": "Jiequan Cui, Zhuotao Tian, Zhisheng Zhong, Xiaojuan Qi, Bei Yu, Hanwang Zhang",
        "footnote": "It uses additional 50M synthetic images in training.",
        "name": "Cui et al. arXiv, May 2023",
        "short": "Cui23"
    },
    "Cui2023Decoupled_WRN-34-10": {
        "url": "https://arxiv.org/abs/2305.13948",
        "paper": "Decoupled Kullback-Leibler Divergence Loss",
        "architecture": "WideResNet-34-10",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "arXiv, May 2023",
        "authors": "Jiequan Cui, Zhuotao Tian, Zhisheng Zhong, Xiaojuan Qi, Bei Yu, Hanwang Zhang",
        "footnote": null,
        "name": "Cui et al. arXiv, May 2023",
        "short": "Cui23"
    },
    "Dai2021Parameterizing": {
        "url": "https://arxiv.org/abs/2110.05626",
        "paper": "Parameterizing Activation Functions for Adversarial Robustness",
        "architecture": "WideResNet-28-10-PSSiLU",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "arXiv, Oct 2021",
        "authors": "Sihui Dai, Saeed Mahloujifar, Prateek Mittal",
        "footnote": "It uses additional ~6M synthetic images in training.",
        "name": "Dai et al. arXiv, Oct 2021",
        "short": "Dai21"
    },
    "Debenedetti2022Light_XCiT-L12": {
        "url": "https://arxiv.org/abs/2209.07399",
        "paper": "A Light Recipe to Train Robust Vision Transformers",
        "architecture": "XCiT-L12",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "arXiv, Sep 2022",
        "authors": "Edoardo Debenedetti, Vikash Sehwag, Prateek Mittal",
        "footnote": null,
        "name": "Debenedetti et al. arXiv, Sep 2022",
        "short": "Debenedetti22"
    },
    "Debenedetti2022Light_XCiT-M12": {
        "url": "https://arxiv.org/abs/2209.07399",
        "paper": "A Light Recipe to Train Robust Vision Transformers",
        "architecture": "XCiT-M12",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "arXiv, Sep 2022",
        "authors": "Edoardo Debenedetti, Vikash Sehwag, Prateek Mittal",
        "footnote": null,
        "name": "Debenedetti et al. arXiv, Sep 2022",
        "short": "Debenedetti22"
    },
    "Debenedetti2022Light_XCiT-S12": {
        "url": "https://arxiv.org/abs/2209.07399",
        "paper": "A Light Recipe to Train Robust Vision Transformers",
        "architecture": "XCiT-S12",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "arXiv, Sep 2022",
        "authors": "Edoardo Debenedetti, Vikash Sehwag, Prateek Mittal",
        "footnote": null,
        "name": "Debenedetti et al. arXiv, Sep 2022",
        "short": "Debenedetti22"
    },
    "Diffenderfer2021Winning_Binary": {
        "url": "https://arxiv.org/abs/2106.09129",
        "paper": "A Winning Hand: Compressing Deep Networks Can Improve Out-Of-Distribution Robustness",
        "architecture": "WideResNet-18-2",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "NeurIPS 2021",
        "authors": "James Diffenderfer, Brian R. Bartoldson, Shreya Chaganti, Jize Zhang, Bhavya Kailkhura",
        "footnote": "Binary weight network trained with AugMix and pruned to 95% sparsity",
        "name": "Diffenderfer et al. NeurIPS 2021",
        "short": "Diffenderfer21"
    },
    "Diffenderfer2021Winning_Binary_CARD_Deck": {
        "url": "https://arxiv.org/abs/2106.09129",
        "paper": "A Winning Hand: Compressing Deep Networks Can Improve Out-Of-Distribution Robustness",
        "architecture": "WideResNet-18-2",
        "additional_data": "False",
        "number_forward_passes": 6,
        "venue": "NeurIPS 2021",
        "authors": "James Diffenderfer, Brian R. Bartoldson, Shreya Chaganti, Jize Zhang, Bhavya Kailkhura",
        "footnote": "Ensemble of binary weight networks each of which are pruned to 95% sparsity",
        "name": "Diffenderfer et al. NeurIPS 2021",
        "short": "Diffenderfer21"
    },
    "Diffenderfer2021Winning_LRR": {
        "url": "https://arxiv.org/abs/2106.09129",
        "paper": "A Winning Hand: Compressing Deep Networks Can Improve Out-Of-Distribution Robustness",
        "architecture": "WideResNet-18-2",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "NeurIPS 2021",
        "authors": "James Diffenderfer, Brian R. Bartoldson, Shreya Chaganti, Jize Zhang, Bhavya Kailkhura",
        "footnote": "Trained with AugMix and pruned to 95% sparsity",
        "name": "Diffenderfer et al. NeurIPS 2021",
        "short": "Diffenderfer21"
    },
    "Diffenderfer2021Winning_LRR_CARD_Deck": {
        "url": "https://arxiv.org/abs/2106.09129",
        "paper": "A Winning Hand: Compressing Deep Networks Can Improve Out-Of-Distribution Robustness",
        "architecture": "WideResNet-18-2",
        "additional_data": "False",
        "number_forward_passes": 6,
        "venue": "NeurIPS 2021",
        "authors": "James Diffenderfer, Brian R. Bartoldson, Shreya Chaganti, Jize Zhang, Bhavya Kailkhura",
        "footnote": "Ensemble of networks each of which are pruned to 95% sparsity",
        "name": "Diffenderfer et al. NeurIPS 2021",
        "short": "Diffenderfer21"
    },
    "Ding2020MMA": {
        "url": "https://openreview.net/forum?id=HkeryxBtPB",
        "paper": "MMA Training: Direct Input Space Margin Maximization through Adversarial Training",
        "architecture": "WideResNet-28-4",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "ICLR 2020",
        "authors": "Gavin Weiguang Ding, Yash Sharma, Kry Yik Chau Lui, Ruitong Huang",
        "footnote": null,
        "name": "Weiguang et al. ICLR 2020",
        "short": "Weiguang20"
    },
    "Engstrom2019Robustness": {
        "url": "https://github.com/MadryLab/robustness",
        "paper": "Robustness library",
        "architecture": "ResNet-50",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "GitHub,<br>Oct 2019",
        "authors": "Logan Engstrom, Andrew Ilyas, Hadi Salman, Shibani Santurkar, Dimitris Tsipras",
        "footnote": null,
        "name": "Engstrom et al. GitHub,<br>Oct 2019",
        "short": "Engstrom19"
    },
    "Erichson2022NoisyMix": {
        "url": "https://arxiv.org/pdf/2202.01263.pdf",
        "paper": "NoisyMix: Boosting Robustness by Combining Data Augmentations, Stability Training, and Noise Injections",
        "architecture": "ResNet-50",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "arXiv, Feb 2022",
        "authors": "N. Benjamin Erichson, Soon Hoe Lim, Francisco Utrera, Winnie Xu, Ziang Cao,, Michael W. Mahoney",
        "footnote": "Basic model.",
        "name": "Benjamin et al. arXiv, Feb 2022",
        "short": "Benjamin22"
    },
    "Gowal2020Uncovering": {
        "url": "https://arxiv.org/abs/2010.03593",
        "paper": "Uncovering the Limits of Adversarial Training against Norm-Bounded Adversarial Examples",
        "architecture": "WideResNet-70-16",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "arXiv, Oct 2020",
        "authors": "Sven Gowal, Chongli Qin, Jonathan Uesato, Timothy Mann, Pushmeet Kohli",
        "footnote": null,
        "name": "Gowal et al. arXiv, Oct 2020",
        "short": "Gowal20"
    },
    "Gowal2020Uncovering_28_10_extra": {
        "url": "https://arxiv.org/abs/2010.03593",
        "paper": "Uncovering the Limits of Adversarial Training against Norm-Bounded Adversarial Examples",
        "architecture": "WideResNet-28-10",
        "additional_data": "True",
        "number_forward_passes": 1,
        "venue": "arXiv, Oct 2020",
        "authors": "Sven Gowal, Chongli Qin, Jonathan Uesato, Timothy Mann, Pushmeet Kohli",
        "footnote": "62.76% robust accuracy is due to the original evaluation (AutoAttack + MultiTargeted)",
        "name": "Gowal et al. arXiv, Oct 2020",
        "short": "Gowal20"
    },
    "Gowal2020Uncovering_34_20": {
        "url": "https://arxiv.org/abs/2010.03593",
        "paper": "Uncovering the Limits of Adversarial Training against Norm-Bounded Adversarial Examples",
        "architecture": "WideResNet-34-20",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "arXiv, Oct 2020",
        "authors": "Sven Gowal, Chongli Qin, Jonathan Uesato, Timothy Mann, Pushmeet Kohli",
        "footnote": "56.82% robust accuracy is due to the original evaluation (AutoAttack + MultiTargeted)",
        "name": "Gowal et al. arXiv, Oct 2020",
        "short": "Gowal20"
    },
    "Gowal2020Uncovering_70_16": {
        "url": "https://arxiv.org/abs/2010.03593",
        "paper": "Uncovering the Limits of Adversarial Training against Norm-Bounded Adversarial Examples",
        "architecture": "WideResNet-70-16",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "arXiv, Oct 2020",
        "authors": "Sven Gowal, Chongli Qin, Jonathan Uesato, Timothy Mann, Pushmeet Kohli",
        "footnote": "57.14% robust accuracy is due to the original evaluation (AutoAttack + MultiTargeted)",
        "name": "Gowal et al. arXiv, Oct 2020",
        "short": "Gowal20"
    },
    "Gowal2020Uncovering_70_16_L2": {
        "url": "https://arxiv.org/abs/2010.03593",
        "paper": "Uncovering the Limits of Adversarial Training against Norm-Bounded Adversarial Examples",
        "architecture": "WideResNet-70-16",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "arXiv, Oct 2020",
        "authors": "Sven Gowal, Chongli Qin, Jonathan Uesato, Timothy Mann, Pushmeet Kohli",
        "footnote": "Trained for \\(\\ell_2 \\) robustness with \\(\\varepsilon = 0.5\\).",
        "name": "Gowal et al. arXiv, Oct 2020",
        "short": "Gowal20"
    },
    "Gowal2020Uncovering_70_16_Linf": {
        "url": "https://arxiv.org/abs/2010.03593",
        "paper": "Uncovering the Limits of Adversarial Training against Norm-Bounded Adversarial Examples",
        "architecture": "WideResNet-70-16",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "arXiv, Oct 2020",
        "authors": "Sven Gowal, Chongli Qin, Jonathan Uesato, Timothy Mann, Pushmeet Kohli",
        "footnote": "Trained for \\(\\ell_{\\infty} \\) robustness with \\(\\varepsilon = 8/255\\).",
        "name": "Gowal et al. arXiv, Oct 2020",
        "short": "Gowal20"
    },
    "Gowal2020Uncovering_70_16_extra": {
        "url": "https://arxiv.org/abs/2010.03593",
        "paper": "Uncovering the Limits of Adversarial Training against Norm-Bounded Adversarial Examples",
        "architecture": "WideResNet-70-16",
        "additional_data": "True",
        "number_forward_passes": 1,
        "venue": "arXiv, Oct 2020",
        "authors": "Sven Gowal, Chongli Qin, Jonathan Uesato, Timothy Mann, Pushmeet Kohli",
        "footnote": "65.87% robust accuracy is due to the original evaluation (AutoAttack + MultiTargeted)",
        "name": "Gowal et al. arXiv, Oct 2020",
        "short": "Gowal20"
    },
    "Gowal2020Uncovering_70_16_extra_L2": {
        "url": "https://arxiv.org/abs/2010.03593",
        "paper": "Uncovering the Limits of Adversarial Training against Norm-Bounded Adversarial Examples",
        "architecture": "WideResNet-70-16",
        "additional_data": "True",
        "number_forward_passes": 1,
        "venue": "arXiv, Oct 2020",
        "authors": "Sven Gowal, Chongli Qin, Jonathan Uesato, Timothy Mann, Pushmeet Kohli",
        "footnote": "Trained for \\(\\ell_2 \\) robustness with \\(\\varepsilon = 0.5\\).",
        "name": "Gowal et al. arXiv, Oct 2020",
        "short": "Gowal20"
    },
    "Gowal2020Uncovering_70_16_extra_Linf": {
        "url": "https://arxiv.org/abs/2010.03593",
        "paper": "Uncovering the Limits of Adversarial Training against Norm-Bounded Adversarial Examples",
        "architecture": "WideResNet-70-16",
        "additional_data": "True",
        "number_forward_passes": 1,
        "venue": "arXiv, Oct 2020",
        "authors": "Sven Gowal, Chongli Qin, Jonathan Uesato, Timothy Mann, Pushmeet Kohli",
        "footnote": "Trained for \\(\\ell_{\\infty} \\) robustness with \\(\\varepsilon = 8/255\\).",
        "name": "Gowal et al. arXiv, Oct 2020",
        "short": "Gowal20"
    },
    "Gowal2020Uncovering_extra": {
        "url": "https://arxiv.org/abs/2010.03593",
        "paper": "Uncovering the Limits of Adversarial Training against Norm-Bounded Adversarial Examples",
        "architecture": "WideResNet-70-16",
        "additional_data": "True",
        "number_forward_passes": 1,
        "venue": "arXiv, Oct 2020",
        "authors": "Sven Gowal, Chongli Qin, Jonathan Uesato, Timothy Mann, Pushmeet Kohli",
        "footnote": null,
        "name": "Gowal et al. arXiv, Oct 2020",
        "short": "Gowal20"
    },
    "Gowal2021Improving_28_10_ddpm_100m": {
        "url": "https://arxiv.org/abs/2110.09468",
        "paper": "Improving Robustness using Generated Data",
        "architecture": "WideResNet-28-10",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "NeurIPS 2021",
        "authors": "Sven Gowal, Sylvestre-Alvise Rebuffi, Olivia Wiles, Florian Stimberg, Dan Andrei Calian, Timothy Mann",
        "footnote": "It uses additional 100M synthetic images in training. 63.38% robust accuracy is due to the original evaluation (AutoAttack + MultiTargeted)",
        "name": "Gowal et al. NeurIPS 2021",
        "short": "Gowal21"
    },
    "Gowal2021Improving_70_16_ddpm_100m": {
        "url": "https://arxiv.org/abs/2110.09468",
        "paper": "Improving Robustness using Generated Data",
        "architecture": "WideResNet-70-16",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "NeurIPS 2021",
        "authors": "Sven Gowal, Sylvestre-Alvise Rebuffi, Olivia Wiles, Florian Stimberg, Dan Andrei Calian, Timothy Mann",
        "footnote": "It uses additional 100M synthetic images in training. 66.10% robust accuracy is due to the original evaluation (AutoAttack + MultiTargeted)",
        "name": "Gowal et al. NeurIPS 2021",
        "short": "Gowal21"
    },
    "Gowal2021Improving_R18_ddpm_100m": {
        "url": "https://arxiv.org/abs/2110.09468",
        "paper": "Improving Robustness using Generated Data",
        "architecture": "PreActResNet-18",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "NeurIPS 2021",
        "authors": "Sven Gowal, Sylvestre-Alvise Rebuffi, Olivia Wiles, Florian Stimberg, Dan Andrei Calian, Timothy Mann",
        "footnote": "It uses additional 100M synthetic images in training. 58.50% robust accuracy is due to the original evaluation (AutoAttack + MultiTargeted)",
        "name": "Gowal et al. NeurIPS 2021",
        "short": "Gowal21"
    },
    "Hendrycks2019Using": {
        "url": "https://arxiv.org/abs/1901.09960",
        "paper": "Using Pre-Training Can Improve Model Robustness and Uncertainty",
        "architecture": "WideResNet-28-10",
        "additional_data": "True",
        "number_forward_passes": 1,
        "venue": "ICML 2019",
        "authors": "Dan Hendrycks, Kimin Lee, Mantas Mazeika",
        "footnote": null,
        "name": "Hendrycks et al. ICML 2019",
        "short": "Hendrycks19"
    },
    "Hendrycks2020AugMix_ResNeXt": {
        "url": "https://arxiv.org/abs/1912.02781",
        "paper": "AugMix: A Simple Data Processing Method to Improve Robustness and Uncertainty",
        "architecture": "ResNeXt29_32x4d",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "ICLR 2020",
        "authors": "Dan Hendrycks, Norman Mu, Ekin D. Cubuk, Barret Zoph, Justin Gilmer, Balaji Lakshminarayanan",
        "footnote": null,
        "name": "Hendrycks et al. ICLR 2020",
        "short": "Hendrycks20"
    },
    "Hendrycks2020AugMix_WRN": {
        "url": "https://arxiv.org/abs/1912.02781",
        "paper": "AugMix: A Simple Data Processing Method to Improve Robustness and Uncertainty",
        "architecture": "WideResNet-40-2",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "ICLR 2020",
        "authors": "Dan Hendrycks, Norman Mu, Ekin D. Cubuk, Barret Zoph, Justin Gilmer, Balaji Lakshminarayanan",
        "footnote": null,
        "name": "Hendrycks et al. ICLR 2020",
        "short": "Hendrycks20"
    },
    "Huang2020Self": {
        "url": "https://arxiv.org/abs/2002.10319",
        "paper": "Self-Adaptive Training: beyond Empirical Risk Minimization",
        "architecture": "WideResNet-34-10",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "NeurIPS 2020",
        "authors": "Lang Huang, Chao Zhang, Hongyang Zhang",
        "footnote": "Uses \\(\\ell_{\\infty} \\) = 0.031 \u2248 7.9/255 instead of 8/255.",
        "name": "Huang et al. NeurIPS 2020",
        "short": "Huang20"
    },
    "Huang2021Exploring": {
        "url": "https://arxiv.org/abs/2110.03825",
        "paper": "Exploring Architectural Ingredients of Adversarially Robust Deep Neural Networks",
        "architecture": "WideResNet-34-R",
        "additional_data": "True",
        "number_forward_passes": 1,
        "venue": "NeurIPS 2021",
        "authors": "Hanxun Huang, Yisen Wang, Sarah Monazam Erfani, Quanquan Gu, James Bailey, Xingjun Ma",
        "footnote": null,
        "name": "Huang et al. NeurIPS 2021",
        "short": "Huang21"
    },
    "Huang2021Exploring_ema": {
        "url": "https://arxiv.org/abs/2110.03825",
        "paper": "Exploring Architectural Ingredients of Adversarially Robust Deep Neural Networks",
        "architecture": "WideResNet-34-R",
        "additional_data": "True",
        "number_forward_passes": 1,
        "venue": "NeurIPS 2021",
        "authors": "Hanxun Huang, Yisen Wang, Sarah Monazam Erfani, Quanquan Gu, James Bailey, Xingjun Ma",
        "footnote": "Uses exponential moving average (EMA)",
        "name": "Huang et al. NeurIPS 2021",
        "short": "Huang21"
    },
    "Huang2022Revisiting_WRN-A4": {
        "url": "https://arxiv.org/abs/2212.11005",
        "paper": "Revisiting Residual Networks for Adversarial Robustness: An Architectural Perspective",
        "architecture": "WideResNet-A4",
        "additional_data": "True",
        "number_forward_passes": 1,
        "venue": "arXiv, Dec. 2022",
        "authors": "Shihua Huang, Zhichao Lu, Kalyanmoy Deb, Vishnu Naresh Boddeti",
        "footnote": null,
        "name": "Huang et al. arXiv, Dec. 2022",
        "short": "Huang22"
    },
    "Jang2019Adversarial": {
        "url": "http://openaccess.thecvf.com/content_ICCV_2019/html/Jang_Adversarial_Defense_via_Learning_to_Generate_Diverse_Attacks_ICCV_2019_paper.html",
        "paper": "Adversarial Defense via Learning to Generate Diverse Attacks",
        "architecture": "ResNet-20",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "ICCV 2019",
        "authors": "Yunseok Jang, Tianchen Zhao, Seunghoon Hong, Honglak Lee",
        "footnote": null,
        "name": "Jang et al. ICCV 2019",
        "short": "Jang19"
    },
    "Jia2022LAS-AT_34_10": {
        "url": "https://arxiv.org/abs/2203.06616",
        "paper": "LAS-AT: Adversarial Training with Learnable Attack Strategy",
        "architecture": "WideResNet-34-10",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "arXiv, Mar 2022",
        "authors": "Xiaojun Jia, Yong Zhang, Baoyuan Wu, Ke Ma, Jue Wang, Xiaochun Cao",
        "footnote": null,
        "name": "Jia et al. arXiv, Mar 2022",
        "short": "Jia22"
    },
    "Jia2022LAS-AT_70_16": {
        "url": "https://arxiv.org/abs/2203.06616",
        "paper": "LAS-AT: Adversarial Training with Learnable Attack Strategy",
        "architecture": "WideResNet-70-16",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "arXiv, Mar 2022",
        "authors": "Xiaojun Jia, Yong Zhang, Baoyuan Wu, Ke Ma, Jue Wang, Xiaochun Cao",
        "footnote": null,
        "name": "Jia et al. arXiv, Mar 2022",
        "short": "Jia22"
    },
    "JinRinard2020Manifold": {
        "url": "https://arxiv.org/abs/2003.04286",
        "paper": "Manifold Regularization for Adversarial Robustness",
        "architecture": "ResNet-18",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "arXiv, Mar 2020",
        "authors": "Charles Jin, Martin Rinard",
        "footnote": null,
        "name": "Jin et al. arXiv, Mar 2020",
        "short": "Jin20"
    },
    "Kang2021Stable": {
        "url": "https://arxiv.org/abs/2110.12976",
        "paper": "Stable Neural ODE with Lyapunov-Stable Equilibrium Points for Defending Against Adversarial Attacks",
        "architecture": "WideResNet-70-16, Neural ODE block",
        "additional_data": "True",
        "number_forward_passes": 1,
        "venue": "NeurIPS 2021",
        "authors": "Qiyu Kang, Yang Song, Qinxu Ding, Wee Peng Tay",
        "footnote": "Based on the model Rebuffi2021Fixing_70_16_cutmix_extra. 64.20% robust accuracy is due to AutoAttack + transfer APGD from Rebuffi2021Fixing_70_16_cutmix_extra",
        "name": "Kang et al. NeurIPS 2021",
        "short": "Kang21"
    },
    "KimWang2020Sensible": {
        "url": "https://openreview.net/forum?id=rJlf_RVKwr",
        "paper": "Sensible adversarial learning",
        "architecture": "WideResNet-34-10",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "OpenReview, Sep 2019",
        "authors": "Jungeum Kim, Xiao Wang",
        "footnote": null,
        "name": "Kim et al. OpenReview, Sep 2019",
        "short": "Kim19"
    },
    "Kireev2021Effectiveness_AugMixNoJSD": {
        "url": "https://arxiv.org/abs/2103.02325",
        "paper": "On the effectiveness of adversarial training against common corruptions",
        "architecture": "PreActResNet-18",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "arXiv, Mar 2021",
        "authors": "Klim Kireev, Maksym Andriushchenko, Nicolas Flammarion",
        "footnote": "Training with AugMix without the JSD term.",
        "name": "Kireev et al. arXiv, Mar 2021",
        "short": "Kireev21"
    },
    "Kireev2021Effectiveness_Gauss50percent": {
        "url": "https://arxiv.org/abs/2103.02325",
        "paper": "On the effectiveness of adversarial training against common corruptions",
        "architecture": "PreActResNet-18",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "arXiv, Mar 2021",
        "authors": "Klim Kireev, Maksym Andriushchenko, Nicolas Flammarion",
        "footnote": "Trained with 50% Gaussian noise per batch. Note: Gaussian noise is contained in CIFAR-10-C.",
        "name": "Kireev et al. arXiv, Mar 2021",
        "short": "Kireev21"
    },
    "Kireev2021Effectiveness_RLAT": {
        "url": "https://arxiv.org/abs/2103.02325",
        "paper": "On the effectiveness of adversarial training against common corruptions",
        "architecture": "PreActResNet-18",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "arXiv, Mar 2021",
        "authors": "Klim Kireev, Maksym Andriushchenko, Nicolas Flammarion",
        "footnote": "Trained with RLAT.",
        "name": "Kireev et al. arXiv, Mar 2021",
        "short": "Kireev21"
    },
    "Kireev2021Effectiveness_RLATAugMix": {
        "url": "https://arxiv.org/abs/2103.02325",
        "paper": "On the effectiveness of adversarial training against common corruptions",
        "architecture": "ResNet-18",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "arXiv, Mar 2021",
        "authors": "Klim Kireev, Maksym Andriushchenko, Nicolas Flammarion",
        "footnote": "Trained with RLAT and AugMix.",
        "name": "Kireev et al. arXiv, Mar 2021",
        "short": "Kireev21"
    },
    "Kireev2021Effectiveness_RLATAugMixNoJSD": {
        "url": "https://arxiv.org/abs/2103.02325",
        "paper": "On the effectiveness of adversarial training against common corruptions",
        "architecture": "PreActResNet-18",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "arXiv, Mar 2021",
        "authors": "Klim Kireev, Maksym Andriushchenko, Nicolas Flammarion",
        "footnote": "Trained with RLAT and AugMix without the JSD term.",
        "name": "Kireev et al. arXiv, Mar 2021",
        "short": "Kireev21"
    },
    "Kumari2019Harnessing": {
        "url": "https://arxiv.org/abs/1905.05186",
        "paper": "Harnessing the Vulnerability of Latent Layers in Adversarially Trained Models",
        "architecture": "WideResNet-34-10",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "IJCAI 2019",
        "authors": "Mayank Singh, Abhishek Sinha, Nupur Kumari, Harshitha Machiraju, Balaji Krishnamurthy, Vineeth N Balasubramanian",
        "footnote": null,
        "name": "Singh et al. IJCAI 2019",
        "short": "Singh19"
    },
    "Kundu2020Tunable": {
        "url": "https://arxiv.org/abs/2011.03083",
        "paper": "A Tunable Robust Pruning Framework Through Dynamic Network Rewiring of DNNs",
        "architecture": "ResNet-18",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "ASP-DAC 2021",
        "authors": "Souvik Kundu, Mahdi Nazemi, Peter A Beerel, Massoud Pedram",
        "footnote": "Compressed model",
        "name": "Kundu et al. ASP-DAC 2021",
        "short": "Kundu21"
    },
    "Madry2018Towards": {
        "url": "https://arxiv.org/abs/1706.06083",
        "paper": "Towards Deep Learning Models Resistant to Adversarial Attacks",
        "architecture": "WideResNet-34-10",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "ICLR 2018",
        "authors": "Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, Adrian Vladu",
        "footnote": null,
        "name": "Madry et al. ICLR 2018",
        "short": "Madry18"
    },
    "Mao2019Metric": {
        "url": "http://papers.nips.cc/paper/8339-metric-learning-for-adversarial-robustness",
        "paper": "Metric Learning for Adversarial Robustness",
        "architecture": "WideResNet-34-10",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "NeurIPS 2019",
        "authors": "Chengzhi Mao, Ziyuan Zhong, Junfeng Yang, Carl Vondrick, Baishakhi Ray",
        "footnote": null,
        "name": "Mao et al. NeurIPS 2019",
        "short": "Mao19"
    },
    "Modas2021PRIMEResNet18": {
        "url": "https://arxiv.org/abs/2112.13547",
        "paper": "PRIME: A Few Primitives Can Boost Robustness to Common Corruptions",
        "architecture": "ResNet-18",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "arXiv, Dec 2021",
        "authors": "Apostolos Modas, Rahul Rade, Guillermo Ortiz-Jim\u00c3\u00a9nez, Seyed-Mohsen Moosavi-Dezfooli, Pascal Frossard",
        "footnote": null,
        "name": "Modas et al. arXiv, Dec 2021",
        "short": "Modas21"
    },
    "Moosavi-Dezfooli2019Robustness": {
        "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Moosavi-Dezfooli_Robustness_via_Curvature_Regularization_and_Vice_Versa_CVPR_2019_paper",
        "paper": "Robustness via Curvature Regularization, and Vice Versa",
        "architecture": "ResNet-18",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "CVPR 2019",
        "authors": "Seyed-Mohsen Moosavi-Dezfooli, Alhussein Fawzi, Jonathan Uesato, Pascal Frossard",
        "footnote": null,
        "name": "Moosavi-Dezfooli et al. CVPR 2019",
        "short": "Moosavi-Dezfooli19"
    },
    "Mustafa2019Adversarial": {
        "url": "https://arxiv.org/abs/1904.00887",
        "paper": "Adversarial Defense by Restricting the Hidden Space of Deep Neural Networks",
        "architecture": "ResNet-110",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "ICCV 2019",
        "authors": "Aamir Mustafa, Salman Khan, Munawar Hayat, Roland Goecke, Jianbing Shen, Ling Shao",
        "footnote": null,
        "name": "Mustafa et al. ICCV 2019",
        "short": "Mustafa19"
    },
    "Pang2020Bag": {
        "url": "https://arxiv.org/abs/2010.00467",
        "paper": "Bag of Tricks for Adversarial Training",
        "architecture": "WideResNet-34-20",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "ICLR 2021",
        "authors": "Tianyu Pang, Xiao Yang, Yinpeng Dong, Hang Su, Jun Zhu",
        "footnote": null,
        "name": "Pang et al. ICLR 2021",
        "short": "Pang21"
    },
    "Pang2020Boosting": {
        "url": "https://arxiv.org/abs/2002.08619",
        "paper": "Boosting Adversarial Training with Hypersphere Embedding",
        "architecture": "WideResNet-34-20",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "NeurIPS 2020",
        "authors": "Tianyu Pang, Xiao Yang, Yinpeng Dong, Kun Xu, Hang Su, Jun Zhu",
        "footnote": null,
        "name": "Pang et al. NeurIPS 2020",
        "short": "Pang20"
    },
    "Pang2020Rethinking": {
        "url": "https://arxiv.org/abs/1905.10626",
        "paper": "Rethinking Softmax Cross-Entropy Loss for Adversarial Robustness",
        "architecture": "ResNet-32",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "ICLR 2020",
        "authors": "Tianyu Pang, Kun Xu, Yinpeng Dong, Chao Du, Ning Chen, Jun Zhu",
        "footnote": null,
        "name": "Pang et al. ICLR 2020",
        "short": "Pang20"
    },
    "Pang2022Robustness_WRN28_10": {
        "url": "https://arxiv.org/pdf/2202.10103.pdf",
        "paper": " Robustness and Accuracy Could Be Reconcilable by (Proper) Definition",
        "architecture": "WideResNet-28-10",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "ICML 2022",
        "authors": "Tianyu Pang, Min Lin, Xiao Yang, Jun Zhu, Shuicheng Yan",
        "footnote": "It uses additional 1M synthetic images in training.",
        "name": "Pang et al. ICML 2022",
        "short": "Pang22"
    },
    "Pang2022Robustness_WRN70_16": {
        "url": "https://arxiv.org/pdf/2202.10103.pdf",
        "paper": " Robustness and Accuracy Could Be Reconcilable by (Proper) Definition",
        "architecture": "WideResNet-70-16",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "ICML 2022",
        "authors": "Tianyu Pang, Min Lin, Xiao Yang, Jun Zhu, Shuicheng Yan",
        "footnote": "It uses additional 1M synthetic images in training.",
        "name": "Pang et al. ICML 2022",
        "short": "Pang22"
    },
    "Peng2023Robust": {
        "url": "https://arxiv.org/abs/2308.16258",
        "paper": "Robust Principles: Architectural Design Principles for Adversarially Robust CNNs",
        "architecture": "RaWideResNet-101-2",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "BMVC 2023",
        "authors": "ShengYun Peng, Weilin Xu, Cory Cornelius, Matthew Hull, Kevin Li, Rahul Duggal, Mansi Phute, Jason Martin,, Duen Horng Chau",
        "footnote": null,
        "name": "Peng et al. BMVC 2023",
        "short": "Peng23"
    },
    "Qin2019Adversarial": {
        "url": "https://arxiv.org/abs/1907.02610v2",
        "paper": "Adversarial Robustness through Local Linearization",
        "architecture": "WideResNet-40-8",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "NeurIPS 2019",
        "authors": "Chongli Qin, James Martens, Sven Gowal, Dilip Krishnan, Krishnamurthy Dvijotham, Alhussein Fawzi, Soham De, Robert Stanforth, Pushmeet Kohli",
        "footnote": null,
        "name": "Qin et al. NeurIPS 2019",
        "short": "Qin19"
    },
    "Rade2021Helper_R18_ddpm": {
        "url": "https://openreview.net/forum?id=BuD2LmNaU3a",
        "paper": "Helper-based Adversarial Training: Reducing Excessive Margin to Achieve a Better Accuracy vs. Robustness Trade-off",
        "architecture": "PreActResNet-18",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "OpenReview, Jun 2021",
        "authors": "Rahul Rade, Seyed-Mohsen Moosavi-Dezfooli",
        "footnote": "It uses additional 1M synthetic images in training.",
        "name": "Rade et al. OpenReview, Jun 2021",
        "short": "Rade21"
    },
    "Rade2021Helper_R18_extra": {
        "url": "https://openreview.net/forum?id=BuD2LmNaU3a",
        "paper": "Helper-based Adversarial Training: Reducing Excessive Margin to Achieve a Better Accuracy vs. Robustness Trade-off",
        "architecture": "PreActResNet-18",
        "additional_data": "True",
        "number_forward_passes": 1,
        "venue": "OpenReview, Jun 2021",
        "authors": "Rahul Rade, Seyed-Mohsen Moosavi-Dezfooli",
        "footnote": null,
        "name": "Rade et al. OpenReview, Jun 2021",
        "short": "Rade21"
    },
    "Rade2021Helper_ddpm": {
        "url": "https://openreview.net/forum?id=BuD2LmNaU3a",
        "paper": "Helper-based Adversarial Training: Reducing Excessive Margin to Achieve a Better Accuracy vs. Robustness Trade-off",
        "architecture": "WideResNet-28-10",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "OpenReview, Jun 2021",
        "authors": "Rahul Rade, Seyed-Mohsen Moosavi-Dezfooli",
        "footnote": "It uses additional 1M synthetic images in training.",
        "name": "Rade et al. OpenReview, Jun 2021",
        "short": "Rade21"
    },
    "Rade2021Helper_extra": {
        "url": "https://openreview.net/forum?id=BuD2LmNaU3a",
        "paper": "Helper-based Adversarial Training: Reducing Excessive Margin to Achieve a Better Accuracy vs. Robustness Trade-off",
        "architecture": "WideResNet-34-10",
        "additional_data": "True",
        "number_forward_passes": 1,
        "venue": "OpenReview, Jun 2021",
        "authors": "Rahul Rade, Seyed-Mohsen Moosavi-Dezfooli",
        "footnote": null,
        "name": "Rade et al. OpenReview, Jun 2021",
        "short": "Rade21"
    },
    "Rebuffi2021Fixing_106_16_cutmix_ddpm": {
        "url": "https://arxiv.org/abs/2103.01946",
        "paper": "Fixing Data Augmentation to Improve Adversarial Robustness",
        "architecture": "WideResNet-106-16",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "arXiv, Mar 2021",
        "authors": "Sylvestre-Alvise Rebuffi, Sven Gowal, Dan A. Calian, Florian Stimberg, Olivia Wiles, Timothy Mann",
        "footnote": "It uses additional 1M synthetic images in training. 64.58% robust accuracy is due to the original evaluation (AutoAttack + MultiTargeted)",
        "name": "Rebuffi et al. arXiv, Mar 2021",
        "short": "Rebuffi21"
    },
    "Rebuffi2021Fixing_28_10_cutmix_ddpm": {
        "url": "https://arxiv.org/abs/2103.01946",
        "paper": "Fixing Data Augmentation to Improve Adversarial Robustness",
        "architecture": "WideResNet-28-10",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "arXiv, Mar 2021",
        "authors": "Sylvestre-Alvise Rebuffi, Sven Gowal, Dan A. Calian, Florian Stimberg, Olivia Wiles, Timothy Mann",
        "footnote": "It uses additional 1M synthetic images in training.",
        "name": "Rebuffi et al. arXiv, Mar 2021",
        "short": "Rebuffi21"
    },
    "Rebuffi2021Fixing_70_16_cutmix_ddpm": {
        "url": "https://arxiv.org/abs/2103.01946",
        "paper": "Fixing Data Augmentation to Improve Adversarial Robustness",
        "architecture": "WideResNet-70-16",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "arXiv, Mar 2021",
        "authors": "Sylvestre-Alvise Rebuffi, Sven Gowal, Dan A. Calian, Florian Stimberg, Olivia Wiles, Timothy Mann",
        "footnote": "It uses additional 1M synthetic images in training.",
        "name": "Rebuffi et al. arXiv, Mar 2021",
        "short": "Rebuffi21"
    },
    "Rebuffi2021Fixing_70_16_cutmix_extra": {
        "url": "https://arxiv.org/abs/2103.01946",
        "paper": "Fixing Data Augmentation to Improve Adversarial Robustness",
        "architecture": "WideResNet-70-16",
        "additional_data": "True",
        "number_forward_passes": 1,
        "venue": "arXiv, Mar 2021",
        "authors": "Sylvestre-Alvise Rebuffi, Sven Gowal, Dan A. Calian, Florian Stimberg, Olivia Wiles, Timothy Mann",
        "footnote": "66.56% robust accuracy is due to the original evaluation (AutoAttack + MultiTargeted)",
        "name": "Rebuffi et al. arXiv, Mar 2021",
        "short": "Rebuffi21"
    },
    "Rebuffi2021Fixing_70_16_cutmix_extra_L2": {
        "url": "https://arxiv.org/abs/2103.01946",
        "paper": "Fixing Data Augmentation to Improve Adversarial Robustness",
        "architecture": "WideResNet-70-16",
        "additional_data": "True",
        "number_forward_passes": 1,
        "venue": "arXiv, Mar 2021",
        "authors": "Sylvestre-Alvise Rebuffi, Sven Gowal, Dan A. Calian, Florian Stimberg, Olivia Wiles, Timothy Mann",
        "footnote": "Trained for \\(\\ell_2 \\) robustness with \\(\\varepsilon = 0.5\\).",
        "name": "Rebuffi et al. arXiv, Mar 2021",
        "short": "Rebuffi21"
    },
    "Rebuffi2021Fixing_70_16_cutmix_extra_Linf": {
        "url": "https://arxiv.org/abs/2103.01946",
        "paper": "Fixing Data Augmentation to Improve Adversarial Robustness",
        "architecture": "WideResNet-70-16",
        "additional_data": "True",
        "number_forward_passes": 1,
        "venue": "arXiv, Mar 2021",
        "authors": "Sylvestre-Alvise Rebuffi, Sven Gowal, Dan A. Calian, Florian Stimberg, Olivia Wiles, Timothy Mann",
        "footnote": "Trained for \\(\\ell_{\\infty} \\) robustness with \\(\\varepsilon = 8/255\\).",
        "name": "Rebuffi et al. arXiv, Mar 2021",
        "short": "Rebuffi21"
    },
    "Rebuffi2021Fixing_R18_cutmix_ddpm": {
        "url": "https://arxiv.org/abs/2103.01946",
        "paper": "Fixing Data Augmentation to Improve Adversarial Robustness",
        "architecture": "PreActResNet-18",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "arXiv, Mar 2021",
        "authors": "Sylvestre-Alvise Rebuffi, Sven Gowal, Dan A. Calian, Florian Stimberg, Olivia Wiles, Timothy Mann",
        "footnote": "It uses additional 1M synthetic images in training.",
        "name": "Rebuffi et al. arXiv, Mar 2021",
        "short": "Rebuffi21"
    },
    "Rebuffi2021Fixing_R18_ddpm": {
        "url": "https://arxiv.org/abs/2103.01946",
        "paper": "Fixing Data Augmentation to Improve Adversarial Robustness",
        "architecture": "PreActResNet-18",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "arXiv, Mar 2021",
        "authors": "Sylvestre-Alvise Rebuffi, Sven Gowal, Dan A. Calian, Florian Stimberg, Olivia Wiles, Timothy Mann",
        "footnote": "It uses additional 1M synthetic images in training.",
        "name": "Rebuffi et al. arXiv, Mar 2021",
        "short": "Rebuffi21"
    },
    "Rice2020Overfitting": {
        "url": "https://arxiv.org/abs/2002.11569",
        "paper": "Overfitting in adversarially robust deep learning",
        "architecture": "PreActResNet-18",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "ICML 2020",
        "authors": "Leslie Rice, Eric Wong, J. Zico Kolter",
        "footnote": null,
        "name": "Rice et al. ICML 2020",
        "short": "Rice20"
    },
    "Rony2019Decoupling": {
        "url": "https://arxiv.org/abs/1811.09600",
        "paper": "Decoupling Direction and Norm for Efficient Gradient-Based L2 Adversarial Attacks and Defenses",
        "architecture": "WideResNet-28-10",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "CVPR 2019",
        "authors": "J\u00e9r\u00f4me Rony, Luiz G. Hafemann, Luiz S. Oliveira, Ismail Ben Ayed, Robert Sabourin, Eric Granger",
        "footnote": null,
        "name": "Rony et al. CVPR 2019",
        "short": "Rony19"
    },
    "Sehwag2020Hydra": {
        "url": "https://arxiv.org/abs/2002.10509",
        "paper": "HYDRA: Pruning Adversarially Robust Neural Networks",
        "architecture": "WideResNet-28-10",
        "additional_data": "True",
        "number_forward_passes": 1,
        "venue": "NeurIPS 2020",
        "authors": "Vikash Sehwag, Shiqi Wang, Prateek Mittal, Suman Jana",
        "footnote": "Compressed model",
        "name": "Sehwag et al. NeurIPS 2020",
        "short": "Sehwag20"
    },
    "Sehwag2021Proxy": {
        "url": "https://arxiv.org/abs/2104.09425",
        "paper": "Robust Learning Meets Generative Models: Can Proxy Distributions Improve Adversarial Robustness?",
        "architecture": "WideResNet-34-10",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "ICLR 2022",
        "authors": "Vikash Sehwag, Saeed Mahloujifar, Tinashe Handina, Sihui Dai, Chong Xiang, Mung Chiang, Prateek Mittal",
        "footnote": "It uses additional 1M synthetic images in training.",
        "name": "Sehwag et al. ICLR 2022",
        "short": "Sehwag22"
    },
    "Sehwag2021Proxy_R18": {
        "url": "https://arxiv.org/abs/2104.09425",
        "paper": "Robust Learning Meets Generative Models: Can Proxy Distributions Improve Adversarial Robustness?",
        "architecture": "ResNet-18",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "ICLR 2022",
        "authors": "Vikash Sehwag, Saeed Mahloujifar, Tinashe Handina, Sihui Dai, Chong Xiang, Mung Chiang, Prateek Mittal",
        "footnote": "It uses additional 10M synthetic images in training.",
        "name": "Sehwag et al. ICLR 2022",
        "short": "Sehwag22"
    },
    "Sehwag2021Proxy_ResNest152": {
        "url": "https://arxiv.org/abs/2104.09425",
        "paper": "Robust Learning Meets Generative Models: Can Proxy Distributions Improve Adversarial Robustness?",
        "architecture": "ResNest152",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "ICLR 2022",
        "authors": "Vikash Sehwag, Saeed Mahloujifar, Tinashe Handina, Sihui Dai, Chong Xiang, Mung Chiang, Prateek Mittal",
        "footnote": "It uses additional 10M synthetic images in training.",
        "name": "Sehwag et al. ICLR 2022",
        "short": "Sehwag22"
    },
    "Shafahi2019Adversarial": {
        "url": "https://arxiv.org/abs/1904.12843",
        "paper": "Adversarial Training for Free!",
        "architecture": "WideResNet-34-10",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "NeurIPS 2019",
        "authors": "Ali Shafahi, Mahyar Najibi, Amin Ghiasi, Zheng Xu, John Dickerson, Christoph Studer, Larry S. Davis, Gavin Taylor, Tom Goldstein",
        "footnote": null,
        "name": "Shafahi et al. NeurIPS 2019",
        "short": "Shafahi19"
    },
    "Sitawarin2020Improving": {
        "url": "https://arxiv.org/abs/2003.09347",
        "paper": "Improving Adversarial Robustness Through Progressive Hardening",
        "architecture": "WideResNet-34-10",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "arXiv, Mar 2020",
        "authors": "Chawin Sitawarin, Supriyo Chakraborty, David Wagner",
        "footnote": null,
        "name": "Sitawarin et al. arXiv, Mar 2020",
        "short": "Sitawarin20"
    },
    "Sridhar2021Robust": {
        "url": "https://arxiv.org/abs/2106.02078",
        "paper": "Improving Neural Network Robustness via Persistency of Excitation",
        "architecture": "WideResNet-28-10",
        "additional_data": "True",
        "number_forward_passes": 1,
        "venue": "ACC 2022",
        "authors": "Kaustubh Sridhar, Oleg Sokolsky, Insup Lee, James Weimer",
        "footnote": null,
        "name": "Sridhar et al. ACC 2022",
        "short": "Sridhar22"
    },
    "Sridhar2021Robust_34_15": {
        "url": "https://arxiv.org/abs/2106.02078",
        "paper": "Improving Neural Network Robustness via Persistency of Excitation",
        "architecture": "WideResNet-34-15",
        "additional_data": "True",
        "number_forward_passes": 1,
        "venue": "ACC 2022",
        "authors": "Kaustubh Sridhar, Oleg Sokolsky, Insup Lee, James Weimer",
        "footnote": null,
        "name": "Sridhar et al. ACC 2022",
        "short": "Sridhar22"
    },
    "Wang2020Improving": {
        "url": "https://openreview.net/forum?id=rklOg6EFwS",
        "paper": "Improving Adversarial Robustness Requires Revisiting Misclassified Examples",
        "architecture": "WideResNet-28-10",
        "additional_data": "True",
        "number_forward_passes": 1,
        "venue": "ICLR 2020",
        "authors": "Yisen Wang, Difan Zou, Jinfeng Yi, James Bailey, Xingjun Ma, Quanquan Gu",
        "footnote": null,
        "name": "Wang et al. ICLR 2020",
        "short": "Wang20"
    },
    "Wang2023Better_WRN-28-10": {
        "url": "https://arxiv.org/abs/2302.04638",
        "paper": "Better Diffusion Models Further Improve Adversarial Training",
        "architecture": "WideResNet-28-10",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "ICML 2023",
        "authors": "Zekai Wang, Tianyu Pang, Chao Du, Min Lin, Weiwei Liu, Shuicheng Yan",
        "footnote": "It uses additional 50M synthetic images in training.",
        "name": "Wang et al. ICML 2023",
        "short": "Wang23"
    },
    "Wang2023Better_WRN-70-16": {
        "url": "https://arxiv.org/abs/2302.04638",
        "paper": "Better Diffusion Models Further Improve Adversarial Training",
        "architecture": "WideResNet-70-16",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "ICML 2023",
        "authors": "Zekai Wang, Tianyu Pang, Chao Du, Min Lin, Weiwei Liu, Shuicheng Yan",
        "footnote": "It uses additional 50M synthetic images in training.",
        "name": "Wang et al. ICML 2023",
        "short": "Wang23"
    },
    "WangZhang2019Bilateral": {
        "url": "http://openaccess.thecvf.com/content_ICCV_2019/html/Wang_Bilateral_Adversarial_Training_Towards_Fast_Training_of_More_Robust_Models_ICCV_2019_paper.html",
        "paper": "Bilateral Adversarial Training: Towards Fast Training of More Robust Models Against Adversarial Attacks",
        "architecture": "WideResNet-28-10",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "ICCV 2019",
        "authors": "Jianyu Wang, Haichao Zhang",
        "footnote": null,
        "name": "Wang et al. ICCV 2019",
        "short": "Wang19"
    },
    "Wong2020Fast": {
        "url": "https://arxiv.org/abs/2001.03994",
        "paper": "Fast is better than free: Revisiting adversarial training",
        "architecture": "ResNet-50",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "ICLR 2020",
        "authors": "Eric Wong, Leslie Rice, J. Zico Kolter",
        "footnote": "Focuses on fast adversarial training.",
        "name": "Wong et al. ICLR 2020",
        "short": "Wong20"
    },
    "Wu2020Adversarial": {
        "url": "https://arxiv.org/abs/2004.05884",
        "paper": "Adversarial Weight Perturbation Helps Robust Generalization",
        "architecture": "WideResNet-34-10",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "NeurIPS 2020",
        "authors": "Dongxian Wu, Shu-tao Xia, Yisen Wang",
        "footnote": null,
        "name": "Wu et al. NeurIPS 2020",
        "short": "Wu20"
    },
    "Wu2020Adversarial_extra": {
        "url": "https://arxiv.org/abs/2004.05884",
        "paper": "Adversarial Weight Perturbation Helps Robust Generalization",
        "architecture": "WideResNet-28-10",
        "additional_data": "True",
        "number_forward_passes": 1,
        "venue": "NeurIPS 2020",
        "authors": "Dongxian Wu, Shu-tao Xia, Yisen Wang",
        "footnote": null,
        "name": "Wu et al. NeurIPS 2020",
        "short": "Wu20"
    },
    "Wu2020Do": {
        "url": "https://arxiv.org/abs/2010.01279",
        "paper": "Do Wider Neural Networks Really Help Adversarial Robustness?",
        "architecture": "WideResNet-34-15",
        "additional_data": "True",
        "number_forward_passes": 1,
        "venue": "arXiv, Oct 2020",
        "authors": "Boxi Wu, Jinghui Chen, Deng Cai, Xiaofei He, Quanquan Gu",
        "footnote": null,
        "name": "Wu et al. arXiv, Oct 2020",
        "short": "Wu20"
    },
    "Xiao2020Enhancing": {
        "url": "https://arxiv.org/abs/1905.10510",
        "paper": "Enhancing Adversarial Defense by k-Winners-Take-All",
        "architecture": "DenseNet-121",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "ICLR 2020",
        "authors": "Chang Xiao, Peilin Zhong, Changxi Zheng",
        "footnote": "Uses \\(\\ell_{\\infty} \\) = 0.031 \u2248 7.9/255 instead of 8/255.<br>7.40% robust accuracy is due to 1 restart of APGD-CE and 30 restarts of Square Attack<br>Note: <a href=\"https://arxiv.org/abs/2002.08347\">this adaptive evaluation</a> (Section 5) reports 0.16% robust accuracy on a different model (adversarially trained ResNet-18).",
        "name": "Xiao et al. ICLR 2020",
        "short": "Xiao20"
    },
    "Xu2023Exploring_WRN-28-10": {
        "url": "https://arxiv.org/abs/2302.03015",
        "paper": "Exploring and Exploiting Decision Boundary Dynamics for Adversarial Robustness",
        "architecture": "WideResNet-28-10",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "ICLR 2023",
        "authors": "Yuancheng Xu, Yanchao Sun, Micah Goldblum, Tom Goldstein, Furong Huang",
        "footnote": "It uses additional 10M synthetic images in training.",
        "name": "Xu et al. ICLR 2023",
        "short": "Xu23"
    },
    "Zhang2019Theoretically": {
        "url": "https://arxiv.org/abs/1901.08573",
        "paper": "Theoretically Principled Trade-off between Robustness and Accuracy",
        "architecture": "WideResNet-34-10",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "ICML 2019",
        "authors": "Hongyang Zhang, Yaodong Yu, Jiantao Jiao, Eric P. Xing, Laurent El Ghaoui, Michael I. Jordan",
        "footnote": "Uses \\(\\ell_{\\infty} \\) = 0.031 \u2248 7.9/255 instead of 8/255.",
        "name": "Zhang et al. ICML 2019",
        "short": "Zhang19"
    },
    "Zhang2019You": {
        "url": "https://arxiv.org/abs/1905.00877",
        "paper": "You Only Propagate Once: Accelerating Adversarial Training via Maximal Principle",
        "architecture": "WideResNet-34-10",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "NeurIPS 2019",
        "authors": "Dinghuai Zhang, Tianyuan Zhang, Yiping Lu, Zhanxing Zhu, Bin Dong",
        "footnote": "Focuses on fast adversarial training.",
        "name": "Zhang et al. NeurIPS 2019",
        "short": "Zhang19"
    },
    "Zhang2020Attacks": {
        "url": "https://arxiv.org/abs/2002.11242",
        "paper": "Attacks Which Do Not Kill Training Make Adversarial Learning Stronger",
        "architecture": "WideResNet-34-10",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "ICML 2020",
        "authors": "Jingfeng Zhang, Xilie Xu, Bo Han, Gang Niu, Lizhen Cui, Masashi Sugiyama, Mohan Kankanhalli",
        "footnote": null,
        "name": "Zhang et al. ICML 2020",
        "short": "Zhang20"
    },
    "Zhang2020Geometry": {
        "url": "https://arxiv.org/abs/2010.01736",
        "paper": "Geometry-aware Instance-reweighted Adversarial Training",
        "architecture": "WideResNet-28-10",
        "additional_data": "True",
        "number_forward_passes": 1,
        "venue": "ICLR 2021",
        "authors": "Jingfeng Zhang, Jianing Zhu, Gang Niu, Bo Han, Masashi Sugiyama, Mohan Kankanhalli",
        "footnote": "Uses \\(\\ell_{\\infty} \\) = 0.031 \u2248 7.9/255 instead of 8/255.",
        "name": "Zhang et al. ICLR 2021",
        "short": "Zhang21"
    },
    "Zhang2020Towards": {
        "url": "https://arxiv.org/abs/1906.06316",
        "paper": "Towards Stable and Efficient Training of Verifiably Robust Neural Networks",
        "architecture": "5-layer-CNN",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "ICLR 2020",
        "authors": "Huan Zhang, Hongge Chen, Chaowei Xiao, Sven Gowal, Robert Stanforth, Bo Li, Duane Boning, Cho-Jui Hsieh",
        "footnote": "Verifiably robust model with 32.24% provable robust accuracy",
        "name": "Zhang et al. ICLR 2020",
        "short": "Zhang20"
    },
    "ZhangWang2019Defense": {
        "url": "http://papers.nips.cc/paper/8459-defense-against-adversarial-attacks-using-feature-scattering-based-adversarial-training",
        "paper": "Defense Against Adversarial Attacks Using Feature Scattering-based Adversarial Training",
        "architecture": "WideResNet-28-10",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "NeurIPS 2019",
        "authors": "Haichao Zhang, Jianyu Wang",
        "footnote": null,
        "name": "Zhang et al. NeurIPS 2019",
        "short": "Zhang19"
    },
    "ZhangXu2020Adversarial": {
        "url": "https://openreview.net/forum?id=Syejj0NYvr&noteId=Syejj0NYvr",
        "paper": "Adversarial Interpolation Training: A Simple Approach for Improving Model Robustness",
        "architecture": "WideResNet-28-10",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "OpenReview, Sep 2019",
        "authors": "Haichao Zhang, Wei Xu",
        "footnote": null,
        "name": "Zhang et al. OpenReview, Sep 2019",
        "short": "Zhang19"
    },
    "Addepalli2021Towards_PARN18": {
        "url": "https://arxiv.org/abs/2210.09852",
        "paper": "Scaling Adversarial Training to Large Perturbation Bounds",
        "architecture": "PreActResNet-18",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "ECCV 2022",
        "authors": "Sravanti Addepalli, Samyak Jain, Gaurang Sriramanan, Shivangi Khare, Venkatesh Babu Radhakrishnan",
        "footnote": null,
        "name": "Addepalli et al. ECCV 2022",
        "short": "Addepalli22"
    },
    "Bai2023Improving_trades": {
        "url": "https://arxiv.org/abs/2301.12554",
        "paper": "Improving the Accuracy-Robustness Trade-off of Classifiers via Adaptive Smoothing",
        "architecture": "ResNet-152 + WideResNet-70-16 + mixing network",
        "additional_data": "True",
        "number_forward_passes": 2,
        "venue": "arXiv, Jan 2023",
        "authors": "Yatong Bai, Brendon G Anderson, Aerin Kim, Somayeh Sojoudi",
        "footnote": "It uses an ensemble of networks.",
        "name": "Bai et al. arXiv, Jan 2023",
        "short": "Bai23"
    },
    "Cui2020Learnable_34_10_LBGAT0": {
        "url": "https://arxiv.org/abs/2011.11164",
        "paper": "Learnable Boundary Guided Adversarial Training",
        "architecture": "WideResNet-34-10",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "ICCV 2021",
        "authors": "Jiequan Cui, Shu Liu, Liwei Wang, Jiaya Jia",
        "footnote": "Uses \\(\\ell_{\\infty} \\) = 0.031 \u2248 7.9/255 instead of 8/255",
        "name": "Cui et al. ICCV 2021",
        "short": "Cui21"
    },
    "Cui2020Learnable_34_10_LBGAT6": {
        "url": "https://arxiv.org/abs/2011.11164",
        "paper": "Learnable Boundary Guided Adversarial Training",
        "architecture": "WideResNet-34-10",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "ICCV 2021",
        "authors": "Jiequan Cui, Shu Liu, Liwei Wang, Jiaya Jia",
        "footnote": "Uses \\(\\ell_{\\infty} \\) = 0.031 \u2248 7.9/255 instead of 8/255",
        "name": "Cui et al. ICCV 2021",
        "short": "Cui21"
    },
    "Cui2020Learnable_34_10_LBGAT9_eps_8_255": {
        "url": "https://arxiv.org/abs/2011.11164",
        "paper": "Learnable Boundary Guided Adversarial Training",
        "architecture": "WideResNet-34-10",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "ICCV 2021",
        "authors": "Jiequan Cui, Shu Liu, Liwei Wang, Jiaya Jia",
        "footnote": "It is combined with AWP.",
        "name": "Cui et al. ICCV 2021",
        "short": "Cui21"
    },
    "Cui2020Learnable_34_20_LBGAT6": {
        "url": "https://arxiv.org/abs/2011.11164",
        "paper": "Learnable Boundary Guided Adversarial Training",
        "architecture": "WideResNet-34-20",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "ICCV 2021",
        "authors": "Jiequan Cui, Shu Liu, Liwei Wang, Jiaya Jia",
        "footnote": "Uses \\(\\ell_{\\infty} \\) = 0.031 \u2248 7.9/255 instead of 8/255",
        "name": "Cui et al. ICCV 2021",
        "short": "Cui21"
    },
    "Cui2023Decoupled_WRN-34-10_autoaug": {
        "url": "https://arxiv.org/abs/2305.13948",
        "paper": "Decoupled Kullback-Leibler Divergence Loss",
        "architecture": "WideResNet-34-10",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "arXiv, May 2023",
        "authors": "Jiequan Cui, Zhuotao Tian, Zhisheng Zhong, Xiaojuan Qi, Bei Yu, Hanwang Zhang",
        "footnote": "It uses AutoAugment.",
        "name": "Cui et al. arXiv, May 2023",
        "short": "Cui23"
    },
    "Gowal2020Uncovering_Linf": {
        "url": "https://arxiv.org/abs/2010.03593",
        "paper": "Uncovering the Limits of Adversarial Training against Norm-Bounded Adversarial Examples",
        "architecture": "WideResNet-70-16",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "arXiv, Oct 2020",
        "authors": "Sven Gowal, Chongli Qin, Jonathan Uesato, Timothy Mann, Pushmeet Kohli",
        "footnote": "Trained for \\(\\ell_{\\infty} \\) robustness with \\(\\varepsilon = 8/255\\).",
        "name": "Gowal et al. arXiv, Oct 2020",
        "short": "Gowal20"
    },
    "Gowal2020Uncovering_extra_Linf": {
        "url": "https://arxiv.org/abs/2010.03593",
        "paper": "Uncovering the Limits of Adversarial Training against Norm-Bounded Adversarial Examples",
        "architecture": "WideResNet-70-16",
        "additional_data": "True",
        "number_forward_passes": 1,
        "venue": "arXiv, Oct 2020",
        "authors": "Sven Gowal, Chongli Qin, Jonathan Uesato, Timothy Mann, Pushmeet Kohli",
        "footnote": "Trained for \\(\\ell_{\\infty} \\) robustness with \\(\\varepsilon = 8/255\\).",
        "name": "Gowal et al. arXiv, Oct 2020",
        "short": "Gowal20"
    },
    "Jia2022LAS-AT_34_20": {
        "url": "https://arxiv.org/abs/2203.06616",
        "paper": "LAS-AT: Adversarial Training with Learnable Attack Strategy",
        "architecture": "WideResNet-34-20",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "arXiv, Mar 2022",
        "authors": "Xiaojun Jia, Yong Zhang, Baoyuan Wu, Ke Ma, Jue Wang, Xiaochun Cao",
        "footnote": null,
        "name": "Jia et al. arXiv, Mar 2022",
        "short": "Jia22"
    },
    "AlexNet": {
        "url": "https://papers.nips.cc/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html",
        "paper": "ImageNet Classification with Deep Convolutional Neural Networks",
        "architecture": "AlexNet",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "NeurIPS 2012",
        "authors": "Alex Krizhevsky, Ilya Sutskever, Geoffrey E. Hinton",
        "footnote": null,
        "name": "Krizhevsky et al. NeurIPS 2012",
        "short": "Krizhevsky12"
    },
    "Erichson2022NoisyMix_new": {
        "url": "https://arxiv.org/pdf/2202.01263.pdf",
        "paper": "NoisyMix: Boosting Robustness by Combining Data Augmentations, Stability Training, and Noise Injections",
        "architecture": "ResNet-50",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "arXiv, Feb 2022",
        "authors": "N. Benjamin Erichson, Soon Hoe Lim, Francisco Utrera, Winnie Xu, Ziang Cao,, Michael W. Mahoney",
        "footnote": "Better tuned model.",
        "name": "Benjamin et al. arXiv, Feb 2022",
        "short": "Benjamin22"
    },
    "Geirhos2018_SIN": {
        "url": "https://arxiv.org/abs/1811.12231",
        "paper": "ImageNet-trained CNNs are biased towards texture; increasing shape bias improves accuracy and robustness",
        "architecture": "ResNet-50",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "ICLR 2019",
        "authors": "Robert Geirhos, Patricia Rubisch, Claudio Michaelis, Matthias Bethge, Felix A. Wichmann, Wieland Brendel",
        "footnote": "Model A: trained on Stylized ImageNet.",
        "name": "Geirhos et al. ICLR 2019",
        "short": "Geirhos19"
    },
    "Geirhos2018_SIN_IN": {
        "url": "https://arxiv.org/abs/1811.12231",
        "paper": "ImageNet-trained CNNs are biased towards texture; increasing shape bias improves accuracy and robustness",
        "architecture": "ResNet-50",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "ICLR 2019",
        "authors": "Robert Geirhos, Patricia Rubisch, Claudio Michaelis, Matthias Bethge, Felix A. Wichmann, Wieland Brendel",
        "footnote": "Model B: trained on Stylized ImageNet and standard ImageNet.",
        "name": "Geirhos et al. ICLR 2019",
        "short": "Geirhos19"
    },
    "Geirhos2018_SIN_IN_IN": {
        "url": "https://arxiv.org/abs/1811.12231",
        "paper": "ImageNet-trained CNNs are biased towards texture; increasing shape bias improves accuracy and robustness",
        "architecture": "ResNet-50",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "ICLR 2019",
        "authors": "Robert Geirhos, Patricia Rubisch, Claudio Michaelis, Matthias Bethge, Felix A. Wichmann, Wieland Brendel",
        "footnote": "Model C: trained on Stylized ImageNet and standard ImageNet, then fine-tuned on standard ImageNet.",
        "name": "Geirhos et al. ICLR 2019",
        "short": "Geirhos19"
    },
    "Hendrycks2020AugMix": {
        "url": "https://arxiv.org/abs/1912.02781",
        "paper": "AugMix: A Simple Data Processing Method to Improve Robustness and Uncertainty",
        "architecture": "ResNet-50",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "ICLR 2020",
        "authors": "Dan Hendrycks, Norman Mu, Ekin D. Cubuk, Barret Zoph, Justin Gilmer, Balaji Lakshminarayanan",
        "footnote": null,
        "name": "Hendrycks et al. ICLR 2020",
        "short": "Hendrycks20"
    },
    "Hendrycks2020Many": {
        "url": "https://arxiv.org/abs/2006.16241",
        "paper": "The Many Faces of Robustness: A Critical Analysis of Out-of-Distribution Generalization",
        "architecture": "ResNet-50",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "ICCV 2021",
        "authors": "Dan Hendrycks, Steven Basart, Norman Mu, Saurav Kadavath, Frank Wang, Evan Dorundo, Rahul Desai, Tyler Zhu, Samyak Parajuli, Mike Guo, Dawn Song, Jacob Steinhardt, Justin Gilmer",
        "footnote": null,
        "name": "Hendrycks et al. ICCV 2021",
        "short": "Hendrycks21"
    },
    "Liu2023Comprehensive_ConvNeXt-B": {
        "url": "https://arxiv.org/abs/2302.14301",
        "paper": "A Comprehensive Study on Robustness of Image Classification Models: Benchmarking and Rethinking",
        "architecture": "ConvNeXt-B",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "arXiv, Feb 2023",
        "authors": "Chang Liu, Yinpeng Dong, Wenzhao Xiang, Xiao Yang, Hang Su, Jun Zhu, Yuefeng Chen, Yuan He, Hui Xue, Shibao Zheng",
        "footnote": null,
        "name": "Liu et al. arXiv, Feb 2023",
        "short": "Liu23"
    },
    "Liu2023Comprehensive_ConvNeXt-L": {
        "url": "https://arxiv.org/abs/2302.14301",
        "paper": "A Comprehensive Study on Robustness of Image Classification Models: Benchmarking and Rethinking",
        "architecture": "ConvNeXt-L",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "arXiv, Feb 2023",
        "authors": "Chang Liu, Yinpeng Dong, Wenzhao Xiang, Xiao Yang, Hang Su, Jun Zhu, Yuefeng Chen, Yuan He, Hui Xue, Shibao Zheng",
        "footnote": null,
        "name": "Liu et al. arXiv, Feb 2023",
        "short": "Liu23"
    },
    "Liu2023Comprehensive_Swin-B": {
        "url": "https://arxiv.org/abs/2302.14301",
        "paper": "A Comprehensive Study on Robustness of Image Classification Models: Benchmarking and Rethinking",
        "architecture": "Swin-B",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "arXiv, Feb 2023",
        "authors": "Chang Liu, Yinpeng Dong, Wenzhao Xiang, Xiao Yang, Hang Su, Jun Zhu, Yuefeng Chen, Yuan He, Hui Xue, Shibao Zheng",
        "footnote": null,
        "name": "Liu et al. arXiv, Feb 2023",
        "short": "Liu23"
    },
    "Liu2023Comprehensive_Swin-L": {
        "url": "https://arxiv.org/abs/2302.14301",
        "paper": "A Comprehensive Study on Robustness of Image Classification Models: Benchmarking and Rethinking",
        "architecture": "Swin-L",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "arXiv, Feb 2023",
        "authors": "Chang Liu, Yinpeng Dong, Wenzhao Xiang, Xiao Yang, Hang Su, Jun Zhu, Yuefeng Chen, Yuan He, Hui Xue, Shibao Zheng",
        "footnote": null,
        "name": "Liu et al. arXiv, Feb 2023",
        "short": "Liu23"
    },
    "Salman2020Do_50_2": {
        "url": "https://arxiv.org/abs/2007.08489",
        "paper": "Do Adversarially Robust ImageNet Models Transfer Better?",
        "architecture": "WideResNet-50-2",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "NeurIPS 2020",
        "authors": "Hadi Salman, Andrew Ilyas, Logan Engstrom, Ashish Kapoor, Aleksander Madry",
        "footnote": null,
        "name": "Salman et al. NeurIPS 2020",
        "short": "Salman20"
    },
    "Salman2020Do_50_2_Linf": {
        "url": "https://arxiv.org/abs/2007.08489",
        "paper": "Do Adversarially Robust ImageNet Models Transfer Better?",
        "architecture": "WideResNet-50-2",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "NeurIPS 2020",
        "authors": "Hadi Salman, Andrew Ilyas, Logan Engstrom, Ashish Kapoor, Aleksander Madry",
        "footnote": null,
        "name": "Salman et al. NeurIPS 2020",
        "short": "Salman20"
    },
    "Salman2020Do_R18": {
        "url": "https://arxiv.org/abs/2007.08489",
        "paper": "Do Adversarially Robust ImageNet Models Transfer Better?",
        "architecture": "ResNet-18",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "NeurIPS 2020",
        "authors": "Hadi Salman, Andrew Ilyas, Logan Engstrom, Ashish Kapoor, Aleksander Madry",
        "footnote": null,
        "name": "Salman et al. NeurIPS 2020",
        "short": "Salman20"
    },
    "Salman2020Do_R50": {
        "url": "https://arxiv.org/abs/2007.08489",
        "paper": "Do Adversarially Robust ImageNet Models Transfer Better?",
        "architecture": "ResNet-50",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "NeurIPS 2020",
        "authors": "Hadi Salman, Andrew Ilyas, Logan Engstrom, Ashish Kapoor, Aleksander Madry",
        "footnote": null,
        "name": "Salman et al. NeurIPS 2020",
        "short": "Salman20"
    },
    "Singh2023Revisiting_ConvNeXt-B-ConvStem": {
        "url": "https://arxiv.org/abs/2303.01870",
        "paper": "Revisiting Adversarial Training for ImageNet: Architectures, Training and Generalization across Threat Models",
        "architecture": "ConvNeXt-B + ConvStem",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "arXiv, Mar 2023",
        "authors": "Naman D Singh, Francesco Croce, Matthias Hein",
        "footnote": null,
        "name": "D et al. arXiv, Mar 2023",
        "short": "D23"
    },
    "Singh2023Revisiting_ConvNeXt-L-ConvStem": {
        "url": "https://arxiv.org/abs/2303.01870",
        "paper": "Revisiting Adversarial Training for ImageNet: Architectures, Training and Generalization across Threat Models",
        "architecture": "ConvNeXt-L + ConvStem",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "arXiv, Mar 2023",
        "authors": "Naman D Singh, Francesco Croce, Matthias Hein",
        "footnote": null,
        "name": "D et al. arXiv, Mar 2023",
        "short": "D23"
    },
    "Singh2023Revisiting_ConvNeXt-S-ConvStem": {
        "url": "https://arxiv.org/abs/2303.01870",
        "paper": "Revisiting Adversarial Training for ImageNet: Architectures, Training and Generalization across Threat Models",
        "architecture": "ConvNeXt-S + ConvStem",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "arXiv, Mar 2023",
        "authors": "Naman D Singh, Francesco Croce, Matthias Hein",
        "footnote": null,
        "name": "D et al. arXiv, Mar 2023",
        "short": "D23"
    },
    "Singh2023Revisiting_ConvNeXt-T-ConvStem": {
        "url": "https://arxiv.org/abs/2303.01870",
        "paper": "Revisiting Adversarial Training for ImageNet: Architectures, Training and Generalization across Threat Models",
        "architecture": "ConvNeXt-T + ConvStem",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "arXiv, Mar 2023",
        "authors": "Naman D Singh, Francesco Croce, Matthias Hein",
        "footnote": null,
        "name": "D et al. arXiv, Mar 2023",
        "short": "D23"
    },
    "Singh2023Revisiting_ViT-B-ConvStem": {
        "url": "https://arxiv.org/abs/2303.01870",
        "paper": "Revisiting Adversarial Training for ImageNet: Architectures, Training and Generalization across Threat Models",
        "architecture": "ViT-B + ConvStem",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "arXiv, Mar 2023",
        "authors": "Naman D Singh, Francesco Croce, Matthias Hein",
        "footnote": null,
        "name": "D et al. arXiv, Mar 2023",
        "short": "D23"
    },
    "Singh2023Revisiting_ViT-S-ConvStem": {
        "url": "https://arxiv.org/abs/2303.01870",
        "paper": "Revisiting Adversarial Training for ImageNet: Architectures, Training and Generalization across Threat Models",
        "architecture": "ViT-S + ConvStem",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "arXiv, Mar 2023",
        "authors": "Naman D Singh, Francesco Croce, Matthias Hein",
        "footnote": null,
        "name": "D et al. arXiv, Mar 2023",
        "short": "D23"
    },
    "Tian2022Deeper_DeiT-B": {
        "url": "https://arxiv.org/abs/2204.12143",
        "paper": "Deeper Insights into the Robustness of ViTs towards Common Corruptions",
        "architecture": "DeiT Base",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "arXiv, Apr 2022",
        "authors": "Rui Tian, Zuxuan Wu, Qi Dai, Han Hu, Yu-Gang Jiang",
        "footnote": null,
        "name": "Tian et al. arXiv, Apr 2022",
        "short": "Tian22"
    },
    "Tian2022Deeper_DeiT-S": {
        "url": "https://arxiv.org/abs/2204.12143",
        "paper": "Deeper Insights into the Robustness of ViTs towards Common Corruptions",
        "architecture": "DeiT Small",
        "additional_data": "False",
        "number_forward_passes": 1,
        "venue": "arXiv, Apr 2022",
        "authors": "Rui Tian, Zuxuan Wu, Qi Dai, Han Hu, Yu-Gang Jiang",
        "footnote": null,
        "name": "Tian et al. arXiv, Apr 2022",
        "short": "Tian22"
    }
}